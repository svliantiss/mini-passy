# Mini-Passy Environment Configuration
# Copy this file to .env and fill in your API keys

# Provider Configuration
# Format: PROVIDER_{NAME}_URL and PROVIDER_{NAME}_KEY
# The {NAME} can be any identifier (lowercase recommended)

PROVIDER_OPENAI_URL=https://api.openai.com
PROVIDER_OPENAI_KEY=sk-your-openai-key-here

PROVIDER_ANTHROPIC_URL=https://api.anthropic.com
PROVIDER_ANTHROPIC_KEY=sk-your-anthropic-key-here

# Example: Add Nebius provider
# PROVIDER_NEBIUS_URL=https://api.studio.nebius.ai
# PROVIDER_NEBIUS_KEY=your-nebius-key-here

# Model Aliases
# Format: ALIAS_{NAME}=provider:model
# Use the provider name from above (lowercase)

ALIAS_GPT4O=openai:gpt-4o
ALIAS_GPT4O_MINI=openai:gpt-4o-mini
ALIAS_CLAUDE_HAIKU=anthropic:claude-3-haiku-20240307
ALIAS_CLAUDE_SONNET=anthropic:claude-3-sonnet-20240229

# Example: Add alias for Nebius model
# ALIAS_LLAMA70B=nebius:meta-llama/Meta-Llama-3.1-70B-Instruct

# Fallback Configuration (optional)
# Format: ALIAS_{NAME}_FALLBACK=provider1,provider2
# If the primary provider fails, it will try these in order

# Example: Try nebius first, fall back to deepinfra
# ALIAS_LLAMA70B_FALLBACK=deepinfra

# Server Configuration
PORT=3333
